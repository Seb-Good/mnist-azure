{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MNIST-Azure\n",
    "## Pipeline Test\n",
    "### By: Sebastian Goodfellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Configure Notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import 3rd party libraries\n",
    "import os\n",
    "import sys\n",
    "import  azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, DataTransferStep\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Import local Libraries\n",
    "sys.path.insert(0, './../')\n",
    "from mnistazure.config import DATA_PATH, TENSORBOARD_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get workspace\n",
    "workspace = Workspace.get(name='mnist-azure', subscription_id='30284b70-31e1-4b93-b620-26959f80a8f9', \n",
    "                          resource_group='spector-ai')\n",
    "\n",
    "# Get file datastore\n",
    "datastore = Datastore.get(workspace=workspace, datastore_name='workspacefilestore')\n",
    "\n",
    "# source directory\n",
    "source_directory = './../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspacefilestore AzureFile\n",
      "workspaceblobstore AzureBlob\n",
      "raw AzureFile\n",
      "train AzureFile\n"
     ]
    }
   ],
   "source": [
    "# View workspace datastores\n",
    "datastores = workspace.datastores\n",
    "for name, ds in datastores.items():\n",
    "    print(name, ds.datastore_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Compute Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aml-compute\n"
     ]
    }
   ],
   "source": [
    "# View available compute targets\n",
    "cts = workspace.compute_targets\n",
    "for ct in cts:\n",
    "    print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n"
     ]
    }
   ],
   "source": [
    "# Create compute target if not available\n",
    "aml_compute_target = 'aml-compute'\n",
    "try:\n",
    "    aml_compute = AmlCompute(workspace=workspace, name=aml_compute_target)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating new compute target')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = 'STANDARD_D2_V2', min_nodes = 1, \n",
    "                                                                max_nodes = 4)    \n",
    "    aml_compute = ComputeTarget.create(workspace=workspace, name=aml_compute_target, \n",
    "                                       provisioning_configuration=provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data reference\n",
    "pl_raw_data_ref = PipelineData(name='pl_raw_data', datastore=datastore, is_directory=True, \n",
    "                               pipeline_output_name='pl_raw_data', output_overwrite=True)\n",
    "\n",
    "# Raw data reference\n",
    "pl_train_data_ref = PipelineData(name='pl_train_data', datastore=datastore, is_directory=True, \n",
    "                                 pipeline_output_name='pl_train_data', output_overwrite=True)\n",
    "\n",
    "# Training data reference\n",
    "train_data_ref = DataReference(datastore=datastore, data_reference_name='train_data', \n",
    "                               path_on_datastore='train_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline\n",
    "### Setup Pipeline Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new runconfig object\n",
    "run_config = RunConfiguration()\n",
    "\n",
    "# Enable Docker \n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# Set Docker base image to the default CPU-based image\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Auto-prepare the Docker image when used for execution (if it is not already prepared)\n",
    "run_config.auto_prepare_environment = True\n",
    "\n",
    "# Specify CondaDependencies obj\n",
    "run_config.environment.python.conda_dependencies = \\\n",
    "    CondaDependencies(conda_dependencies_file_path='./../pipeline_env.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST dataset to pipeline data object\n",
    "step_1 = PythonScriptStep(script_name='pipeline_1.py', arguments=['--output', pl_raw_data_ref], \n",
    "                          inputs=None, outputs=[pl_raw_data_ref], compute_target=aml_compute, \n",
    "                          source_directory=source_directory, runconfig=run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creating Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "step_2 = PythonScriptStep(script_name='pipeline_2.py', \n",
    "                          arguments=['--input', pl_raw_data_ref, '--output', pl_train_data_ref], \n",
    "                          inputs=[pl_raw_data_ref], outputs=[pl_train_data_ref], compute_target=aml_compute, \n",
    "                          source_directory=source_directory, runconfig=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build Pipeline object\n",
    "pipeline = Pipeline(workspace=workspace, steps=[step_1, step_2])\n",
    "\n",
    "# Submit pipeline job\n",
    "pipeline_run = Experiment(workspace=workspace, name='Data_dependency').submit(pipeline, regenerate_outputs=False)\n",
    "RunDetails(pipeline_run).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
